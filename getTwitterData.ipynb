{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Twitter - Historical Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "1. Get Python >= 3.8.0\n",
    "2. Install:\n",
    "\n",
    "```$:> pip install git+https://github.com/JustAnotherArchivist/snscrape.git```\n",
    "\n",
    "```$:> pip install snscrape```\n",
    "\n",
    "3. Set: `start_date` = \"YYYY-MM-DD\", `end_date` = \"YYYY-MM-DD\"\n",
    "4. Run  `get_tweets()`\n",
    "5. Save output df in a CSV format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from ast import literal_eval\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import snscrape.modules.twitter as sntwitter # the magic\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.abspath(os.path.join(os.path.dirname(\".\"), '.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extractor Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractTweets:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 minTweetCountPerDay=10, \n",
    "                 minRetweetCount=0,\n",
    "                 minLikeCount=0, \n",
    "                 minFollowersCount=0, \n",
    "                 VerifiedStatus=None, \n",
    "                 saveBufferDuration=3600):\n",
    "        \"\"\"\n",
    "        Accepts basic input params each of integer datatype, except for VerifiedStatus which accepts boolean or None.\n",
    "        \"\"\"\n",
    "        self.start_timer = datetime.strptime(time.strftime(\"%Y-%m-%d %H:%M:%S\"), \"%Y-%m-%d %H:%M:%S\")\n",
    "        self.min_tweet_count_perDay = minTweetCountPerDay\n",
    "        self.minRetweetCount = minRetweetCount\n",
    "        self.minLikeCount = minLikeCount\n",
    "        self.minFollowersCount = minFollowersCount\n",
    "        self.VerifiedStatus = VerifiedStatus                           \n",
    "        self.tweets_df = pd.DataFrame(columns=['date', 'tweet', 'lang', 'retweetCount', 'likeCount', 'replyCount', \n",
    "                                               'username', 'user_followersCount','user_friendsCount', 'verifiedStatus', \n",
    "                                               'tweet_url', 'hastags', 'chr_count', 'topic'])\n",
    "        self.save_buffer_duration = saveBufferDuration\n",
    "        return\n",
    "\n",
    "    def save_copy(self):\n",
    "        \"\"\"\n",
    "        Saves a temp copy for restoration and prevent API time limit exceed error.\n",
    "        \n",
    "        :return:\n",
    "        pandas dataframe containing twitter record-data.\n",
    "        \"\"\"\n",
    "        data = self.tweets_df.reset_index(drop=True)\n",
    "        data['date'] = data['date'].apply(lambda x: pd.to_datetime(x).strftime('%Y-%m-%d'))\n",
    "        for filename in os.listdir(\".\"):\n",
    "            if filename.endswith('local.csv'):\n",
    "                os.remove(filename)\n",
    "        data.to_csv(\"./save_{}_local.csv\".format(data.date.max()), index=False)\n",
    "        return data\n",
    "        \n",
    "    def getTweets(self, start_date, end_date, keywords):\n",
    "        \"\"\"\n",
    "        Extracts historical twitter data.\n",
    "        \n",
    "        :params:\n",
    "        start_date - str in \"YYYY-MM-DD\" format\n",
    "        end_date - str in \"YYYY-MM-DD\" format\n",
    "        keywords - list of tuples, \n",
    "            e.g, [('recession'), ('football, 'worldcup', 'fifa'), ('war', 'ukraine')]\n",
    "            e.g. ['recession']\n",
    "        \n",
    "        :return:\n",
    "        pandas dataframe with features as:\n",
    "         date: Tweet Timestamp\n",
    "         tweet: tweet content\n",
    "         lang: language classifer used by parent api\n",
    "         retweetCount: tweet retweeted count\n",
    "         likeCount: tweet like count\n",
    "         replyCount: number of replies to original tweet\n",
    "         username: user who tweeted\n",
    "         user_followersCount: number of followers user has (tells you how popular the avg tweets are)\n",
    "         user_friendsCount: number of friends user has\n",
    "         verifiedStatus: If the user is Verified or not (i.e. pays 8 bucks every month!)\n",
    "         tweet_url: Link of original tweet (click and see)\n",
    "         hastags: If any hastags were used (hastags are important for search and info retrieval)\n",
    "         chr_count: number of english characters in the original tweet\n",
    "         topic: keywords you used for searching tweets (kind of labels)\n",
    "        \"\"\"\n",
    "        \n",
    "        if not(isinstance(keywords, list) or isinstance(keywords, tuple)):\n",
    "            raise Exception(\"Incorrect Input Format! Please pass a list\")\n",
    "        \n",
    "        for topic in keywords:\n",
    "            # for saving local copies every buffer_hour\n",
    "            st_time = datetime.strptime(time.strftime(\"%Y-%m-%d %H:%M:%S\"), \"%Y-%m-%d %H:%M:%S\")\n",
    "            date = pd.to_datetime(start_date, format='%Y-%m-%d')\n",
    "            e_date = pd.to_datetime(end_date, format='%Y-%m-%d') + pd.to_timedelta(1, unit='d')\n",
    "            if isinstance(topic, tuple) or isinstance(topic, list):\n",
    "                topic = \" \".join(topic)\n",
    "            search_query = topic\n",
    "            print(\"search_query:\", search_query)\n",
    "        \n",
    "            while date != e_date:\n",
    "                nxt_date = date + pd.to_timedelta(1, unit='d')\n",
    "                content = '{} since:{} until:{}'.format(search_query, date.strftime('%Y-%m-%d'), nxt_date.strftime('%Y-%m-%d'))\n",
    "                print(content)\n",
    "                \n",
    "                # check for save buffer duration (set to 1 Hr by default)\n",
    "                delta_buffer = (datetime.strptime(time.strftime(\"%Y-%m-%d %H:%M:%S\"), \"%Y-%m-%d %H:%M:%S\") - st_time).seconds\n",
    "                if delta_buffer >= self.save_buffer_duration:\n",
    "                    self.save_copy()\n",
    "                    # reset buffer\n",
    "                    st_time = datetime.strptime(time.strftime(\"%Y-%m-%d %H:%M:%S\"), \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "                lst_tweets = []\n",
    "                for counter, tweet in enumerate(sntwitter.TwitterSearchScraper(content).get_items()):\n",
    "                    if counter+1 > self.min_tweet_count_perDay: \n",
    "                        break\n",
    "                    if tweet.likeCount >= self.minLikeCount \\\n",
    "                        or tweet.retweetCount >= self.minRetweetCount \\\n",
    "                        or tweet.user.followersCount >= self.minFollowersCount \\\n",
    "                        or (tweet.user.verified and isinstance(tweet.user.verified, bool) and tweet.user.verified == self.VerifiedStatus):\n",
    "                        \n",
    "                        # ----------------------------------------------------------------\n",
    "                        # Potential custom preprocessing module here: \n",
    "                        # 1. Simple and short: https://www.kaggle.com/code/zenbird01/pranjalpathak-semantic-clustering-v1-0/notebook\n",
    "                        # 2. Advanced: ./NLP_basics_preprocessing_vectorization_similarity.ipynb\n",
    "                        # 3. Best: Check github - https://github.com/pranzell/NLP_Tools\n",
    "                        # ----------------------------------------------------------------\n",
    "                        \n",
    "                        lst_tweets.append([\n",
    "                            tweet.date, \n",
    "                            tweet.content, \n",
    "                            tweet.lang,\n",
    "                            tweet.retweetCount,\n",
    "                            tweet.likeCount,\n",
    "                            tweet.replyCount,\n",
    "                            tweet.user.username, \n",
    "                            tweet.user.followersCount, \n",
    "                            tweet.user.friendsCount, \n",
    "                            tweet.user.verified,\n",
    "                            tweet.url,\n",
    "                            tweet.hashtags,\n",
    "                            len(str(tweet.content).strip()),\n",
    "                            topic])\n",
    "                \n",
    "                self.tweets_df = self.tweets_df.append(pd.DataFrame(lst_tweets, columns=self.tweets_df.columns))\n",
    "                date = nxt_date\n",
    "        \n",
    "        print(\"\\n\\nTOTAL TIME TAKEN {} minutes\".format(((datetime.strptime(time.strftime(\"%Y-%m-%d %H:%M:%S\"), \"%Y-%m-%d %H:%M:%S\") - self.start_timer).seconds)/60.0))\n",
    "        return self.save_copy()\n",
    "    \n",
    "    \n",
    "    def preprocess_shortText(self, text_col):\n",
    "        # refer to Preprocessing ipynb file\n",
    "        # https://github.com/pranzell/NLP_Tools\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <ins>Execute</ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "minTweetCountPerDay=50\n",
    "minRetweetCount=100\n",
    "minLikeCount=100\n",
    "minFollowersCount=200\n",
    "VerifiedStatus=None\n",
    "saveBufferDuration=3600 # in seconds\n",
    "\n",
    "start_date = \"2023-01-01\"\n",
    "end_date = \"2023-01-05\"\n",
    "\n",
    "# list of tuples, or a list of single str items check function definition `getTweets()`\n",
    "keywords = [('recession'), ('football', \"fifaworldcup\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_query: recession\n",
      "recession since:2023-01-01 until:2023-01-02\n",
      "recession since:2023-01-02 until:2023-01-03\n",
      "recession since:2023-01-03 until:2023-01-04\n",
      "recession since:2023-01-04 until:2023-01-05\n",
      "recession since:2023-01-05 until:2023-01-06\n",
      "search_query: football fifaworldcup\n",
      "football fifaworldcup since:2023-01-01 until:2023-01-02\n",
      "football fifaworldcup since:2023-01-02 until:2023-01-03\n",
      "football fifaworldcup since:2023-01-03 until:2023-01-04\n",
      "football fifaworldcup since:2023-01-04 until:2023-01-05\n",
      "football fifaworldcup since:2023-01-05 until:2023-01-06\n",
      "\n",
      "\n",
      "TOTAL TIME TAKEN 0.5 minutes\n"
     ]
    }
   ],
   "source": [
    "et = ExtractTweets(minTweetCountPerDay, minRetweetCount, minLikeCount, minFollowersCount, VerifiedStatus, saveBufferDuration)\n",
    "twitter_data = et.getTweets(start_date, end_date, keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(259, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>lang</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>username</th>\n",
       "      <th>user_followersCount</th>\n",
       "      <th>user_friendsCount</th>\n",
       "      <th>verifiedStatus</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>hastags</th>\n",
       "      <th>chr_count</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Andy thinks a “logical” extreme of prochoice i...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>ShiroSpirit</td>\n",
       "      <td>533</td>\n",
       "      <td>509</td>\n",
       "      <td>False</td>\n",
       "      <td>https://twitter.com/ShiroSpirit/status/1609700...</td>\n",
       "      <td>None</td>\n",
       "      <td>149</td>\n",
       "      <td>recession</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>@fairwaycards There’s a recession in discretio...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>marketmodel</td>\n",
       "      <td>12968</td>\n",
       "      <td>426</td>\n",
       "      <td>False</td>\n",
       "      <td>https://twitter.com/marketmodel/status/1609700...</td>\n",
       "      <td>None</td>\n",
       "      <td>82</td>\n",
       "      <td>recession</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Cierren las escotillas y prepárense. Se viene ...</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>JuanoAbarca</td>\n",
       "      <td>725</td>\n",
       "      <td>2407</td>\n",
       "      <td>False</td>\n",
       "      <td>https://twitter.com/JuanoAbarca/status/1609700...</td>\n",
       "      <td>None</td>\n",
       "      <td>165</td>\n",
       "      <td>recession</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>@saxena_puru The most widely forecasted recess...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>realDillonEvans</td>\n",
       "      <td>2663</td>\n",
       "      <td>1988</td>\n",
       "      <td>False</td>\n",
       "      <td>https://twitter.com/realDillonEvans/status/160...</td>\n",
       "      <td>None</td>\n",
       "      <td>148</td>\n",
       "      <td>recession</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Interesting quote: “Our main message to invest...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>Josh_Young_1</td>\n",
       "      <td>74101</td>\n",
       "      <td>1075</td>\n",
       "      <td>False</td>\n",
       "      <td>https://twitter.com/Josh_Young_1/status/160970...</td>\n",
       "      <td>None</td>\n",
       "      <td>280</td>\n",
       "      <td>recession</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                              tweet lang  \\\n",
       "0  2023-01-01  Andy thinks a “logical” extreme of prochoice i...   en   \n",
       "1  2023-01-01  @fairwaycards There’s a recession in discretio...   en   \n",
       "2  2023-01-01  Cierren las escotillas y prepárense. Se viene ...   es   \n",
       "3  2023-01-01  @saxena_puru The most widely forecasted recess...   en   \n",
       "4  2023-01-01  Interesting quote: “Our main message to invest...   en   \n",
       "\n",
       "  retweetCount likeCount replyCount         username user_followersCount  \\\n",
       "0            0        15          3      ShiroSpirit                 533   \n",
       "1            0         0          0      marketmodel               12968   \n",
       "2            0         1          1      JuanoAbarca                 725   \n",
       "3            0         0          6  realDillonEvans                2663   \n",
       "4            0        18          1     Josh_Young_1               74101   \n",
       "\n",
       "  user_friendsCount verifiedStatus  \\\n",
       "0               509          False   \n",
       "1               426          False   \n",
       "2              2407          False   \n",
       "3              1988          False   \n",
       "4              1075          False   \n",
       "\n",
       "                                           tweet_url hastags chr_count  \\\n",
       "0  https://twitter.com/ShiroSpirit/status/1609700...    None       149   \n",
       "1  https://twitter.com/marketmodel/status/1609700...    None        82   \n",
       "2  https://twitter.com/JuanoAbarca/status/1609700...    None       165   \n",
       "3  https://twitter.com/realDillonEvans/status/160...    None       148   \n",
       "4  https://twitter.com/Josh_Young_1/status/160970...    None       280   \n",
       "\n",
       "       topic  \n",
       "0  recession  \n",
       "1  recession  \n",
       "2  recession  \n",
       "3  recession  \n",
       "4  recession  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(twitter_data.shape)\n",
    "twitter_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_copy(path=\".\"):\n",
    "    for f in os.listdir(path):\n",
    "        if f.endswith('local.csv'):\n",
    "            df = pd.read_csv(f, lineterminator='\\n')\n",
    "            df.hastags = df.hastags.apply(lambda x: literal_eval(x) if str(x) not in ['none', 'nan', 'np.nan', 'null', ''] else None)\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = read_copy(root_dir)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credits to the awesome social media mining tool SNScrape (https://github.com/JustAnotherArchivist/snscrape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_3.8",
   "language": "python",
   "name": "python_3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
